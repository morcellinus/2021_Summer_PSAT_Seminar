{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction_for_sub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR2sRkmRKjELzYw6nd006v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morcellinus/2021_Summer_PSAT_Seminar/blob/main/Prediction_for_sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwOhmdrsLgAh"
      },
      "source": [
        "### 1. 데이터 불러오기, 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwEMcrLoLMlf"
      },
      "source": [
        "# 드라이브 마운트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 라이브러리 설치\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from lightgbm import LGBMClassifier\n",
        "import sklearn.metrics as metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "# 적합시킬 test data 불러오기\n",
        "train=pd.read_csv(\"/content/drive/Shareddrives/🍕PSAT_Summer_Seminar_Team1🍕/Data/train.csv\")\n",
        "test=pd.read_csv(\"/content/drive/Shareddrives/🍕PSAT_Summer_Seminar_Team1🍕/Data/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPF33MxfL8g0"
      },
      "source": [
        "### 2. 모델 학습 (Modelling_for_sub 반복)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWIbwnBHHQIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08824222-ad40-4f31-813d-397f233f9a3f"
      },
      "source": [
        "def numeric_cols(input_df):\n",
        "\n",
        "    # train data에서 수치형 변수만 뽑아냄\n",
        "\n",
        "    print(input_df.select_dtypes('number').columns)\n",
        "    sel_train = input_df.select_dtypes('number').columns.values\n",
        "    print(type(sel_train))\n",
        "\n",
        "    # 수치형 변수만 갖는 데이터프레임 생성\n",
        "\n",
        "    train = input_df[sel_train]\n",
        "    print(train.describe())\n",
        "    return train\n",
        "\n",
        "def balanced_sampling(input_df, factor): \n",
        "    \n",
        "    # 앞서 만든 함수로 수치형 변수만 갖는 데이터프레임 불러옴\n",
        "\n",
        "    train = numeric_cols(input_df)\n",
        "    y= train['target']\n",
        "    \n",
        "    # Target이 1인 row와 Target이 0인 row를 나누고 각각의 row 개수를 셈\n",
        "\n",
        "    X_one = train[train.target==1]\n",
        "    X_zero= train[train.target==0]\n",
        "    total_target = X_one.shape\n",
        "    print(\"Target Size : \",total_target[1],total_target[0])\n",
        "\n",
        "    # 여기서 factor는 함수 호출시 입력받는 숫자\n",
        "\n",
        "    scale_factor = factor\n",
        "\n",
        "    # Target이 0인 row 개수가 더 많으므로 factor 곱하기 Target이 1인 row 개수만큼만 Target이 0인 row에서 샘플링\n",
        "\n",
        "    X_zero1=X_zero.sample(scale_factor*total_target[0], random_state = 1)\n",
        "\n",
        "    # 샘플링된 row와 Target이 1인 row를 합쳐서 새로운 데이터프레임 생성\n",
        "\n",
        "    X=pd.concat([X_one,X_zero1], ignore_index=True)\n",
        "    y= X['target']\n",
        "    print(X.shape)\n",
        "    print(X.sample(10))\n",
        "\n",
        "    \n",
        "    X.drop([\"target\"],axis=1,inplace=True)\n",
        "    \n",
        "    # 새로 만든 데이터프레임으로 train test split\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=0.25, random_state = 1)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Data Rebalancing\n",
        "\n",
        "X_train, X_test, y_train, y_test = balanced_sampling(train,3)\n",
        "\n",
        "# RandomSearchCV로 찾은 최적파라미터들로 모델 생성\n",
        "\n",
        "lgb = LGBMClassifier(bagging_fraction=0.85, bagging_freq=1, boost='gbdt',\n",
        "               boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
        "               feature_fraction=1, gamma=1, importance_type='split',\n",
        "               learning_rate=0.1, max_bin=256, max_depth=1,\n",
        "               min_child_samples=153, min_child_weight=0.1, min_split_gain=0.0,\n",
        "               n_estimators=4000, n_jobs=-1, num_leaves=4, num_threads=8,\n",
        "               objective='binary', random_state=1, reg_alpha=0.1,\n",
        "               reg_lambda=0, seed=500, silent=True, subsample=0.8,\n",
        "               subsample_for_bin=200000, subsample_freq=0)\n",
        "\n",
        "# 모델 학습\n",
        "\n",
        "lgb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',\n",
            "       'var_7', 'var_8',\n",
            "       ...\n",
            "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
            "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
            "      dtype='object', length=201)\n",
            "<class 'numpy.ndarray'>\n",
            "             target         var_0  ...       var_198       var_199\n",
            "count  28000.000000  28000.000000  ...  28000.000000  28000.000000\n",
            "mean       0.100321     10.685383  ...     15.877575     -3.356697\n",
            "std        0.300433      3.065415  ...      3.004946     10.391826\n",
            "min        0.000000      1.283200  ...      7.193200    -38.852800\n",
            "25%        0.000000      8.451800  ...     13.824100    -11.219350\n",
            "50%        0.000000     10.525650  ...     15.944500     -2.868650\n",
            "75%        0.000000     12.763600  ...     18.063550      4.766275\n",
            "max        1.000000     19.701100  ...     25.323000     26.468800\n",
            "\n",
            "[8 rows x 201 columns]\n",
            "Target Size :  201 2809\n",
            "(11236, 201)\n",
            "       target    var_0   var_1    var_2  ...  var_196  var_197  var_198  var_199\n",
            "3280        0  10.0183 -8.4751   8.9160  ...  -1.7656   9.2421  17.7515  -7.3668\n",
            "9787        0   8.8866 -0.9857  10.1055  ...  -2.1271   9.5324  15.7090  -3.4980\n",
            "10746       0  10.0827 -2.2695  12.9097  ...   5.8562   7.2828  13.2917 -14.1826\n",
            "7028        0   9.3395 -2.4273  10.7945  ...  -0.1438   9.3601  13.4435 -14.2428\n",
            "6715        0  11.9327  0.9517  11.6777  ...   5.1026   9.8219  16.8789  -4.0451\n",
            "6197        0  18.2213 -6.3042   5.2946  ...  -0.7447   8.3223  20.4140 -14.9898\n",
            "8930        0  10.2402 -4.8280   7.4548  ...   8.8615  11.2262  19.1029  -0.1648\n",
            "10888       0  12.7107  4.6482  10.2208  ...   3.6088  10.0215  16.3642   8.8789\n",
            "4428        0   7.5803 -3.8323   7.3444  ...   5.0693   9.3728  12.2653  -5.4083\n",
            "11067       0  15.1501 -5.6111  11.2973  ...   6.9884   6.8049  19.2438  12.9225\n",
            "\n",
            "[10 rows x 201 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.85, bagging_freq=1, boost='gbdt',\n",
              "               boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
              "               feature_fraction=1, gamma=1, importance_type='split',\n",
              "               learning_rate=0.1, max_bin=256, max_depth=1,\n",
              "               min_child_samples=153, min_child_weight=0.1, min_split_gain=0.0,\n",
              "               n_estimators=4000, n_jobs=-1, num_leaves=4, num_threads=8,\n",
              "               objective='binary', random_state=1, reg_alpha=0.1, reg_lambda=0,\n",
              "               seed=500, silent=True, subsample=0.8, subsample_for_bin=200000,\n",
              "               subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBflDSFFKbeI"
      },
      "source": [
        "### 3. 모델 적합 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX2yogjxNvoA"
      },
      "source": [
        "y_pred = lgb.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBdTrPceMHeC"
      },
      "source": [
        "### 4. 제출용 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rES6qmcDMKIY"
      },
      "source": [
        "df=pd.DataFrame({'target':y_pred})\n",
        "df=df.reset_index(drop=False)\n",
        "df['index']=df['index'].apply(lambda x: x+1)\n",
        "df.columns=['id','target']\n",
        "df.to_csv(\"/content/drive/Shareddrives/🍕PSAT_Summer_Seminar_Team1🍕/Data/TEAM1_for_submission.csv\",encoding='utf-8-sig',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}