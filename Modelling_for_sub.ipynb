{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelling_for_sub.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHXIfDVZZLIhaf/WFSXfj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morcellinus/2021_Summer_PSAT_Seminar/blob/main/Modelling_for_sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkY5aMfPGk0F"
      },
      "source": [
        "### 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ldIkJmUGxhd",
        "outputId": "c3f3f5a4-8396-4b99-d4de-874c0d9c70c2"
      },
      "source": [
        "# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from lightgbm import LGBMClassifier\n",
        "import sklearn.metrics as metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "train=pd.read_csv(\"/content/drive/Shareddrives/ğŸ•PSAT_Summer_Seminar_Team1ğŸ•/Data/train.csv\")\n",
        "test=pd.read_csv(\"/content/drive/Shareddrives/ğŸ•PSAT_Summer_Seminar_Team1ğŸ•/Data/test.csv\")\n",
        "\n",
        "# Train dataì˜ Feature ë³€ìˆ˜ì™€ Target ë³€ìˆ˜ ë”°ë¡œ ì €ì¥\n",
        "\n",
        "X=train.iloc[:,1:]\n",
        "y=train['target']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y1X5ma7HFLs"
      },
      "source": [
        "# ì†Œìš”ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ íƒ€ì´ë¨¸ ì„¸íŒ… \n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def timer(start_time=None):\n",
        "    if not start_time:\n",
        "        start_time = datetime.now()\n",
        "        return start_time\n",
        "    elif start_time:\n",
        "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
        "        tmin, tsec = divmod(temp_sec, 60)\n",
        "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t450jI32HLUU"
      },
      "source": [
        "### 2. Made Rebalancing Method (ëª¨ë¸ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ìƒ˜í”Œë§ í•¨ìˆ˜) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWIbwnBHHQIO"
      },
      "source": [
        "def numeric_cols(input_df):\n",
        "\n",
        "    # train dataì—ì„œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ë½‘ì•„ëƒ„\n",
        "\n",
        "    print(input_df.select_dtypes('number').columns)\n",
        "    sel_train = input_df.select_dtypes('number').columns.values\n",
        "    print(type(sel_train))\n",
        "\n",
        "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ê°–ëŠ” ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
        "\n",
        "    train = input_df[sel_train]\n",
        "    print(train.describe())\n",
        "    return train\n",
        "\n",
        "def balanced_sampling(input_df, factor): \n",
        "    \n",
        "    # ì•ì„œ ë§Œë“  í•¨ìˆ˜ë¡œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ê°–ëŠ” ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜´\n",
        "\n",
        "    train = numeric_cols(input_df)\n",
        "    y= train['target']\n",
        "    \n",
        "    # Targetì´ 1ì¸ rowì™€ Targetì´ 0ì¸ rowë¥¼ ë‚˜ëˆ„ê³  ê°ê°ì˜ row ê°œìˆ˜ë¥¼ ì…ˆ\n",
        "\n",
        "    X_one = train[train.target==1]\n",
        "    X_zero= train[train.target==0]\n",
        "    total_target = X_one.shape\n",
        "    print(\"Target Size : \",total_target[1],total_target[0])\n",
        "\n",
        "    # ì—¬ê¸°ì„œ factorëŠ” í•¨ìˆ˜ í˜¸ì¶œì‹œ ì…ë ¥ë°›ëŠ” ìˆ«ì\n",
        "\n",
        "    scale_factor = factor\n",
        "\n",
        "    # Targetì´ 0ì¸ row ê°œìˆ˜ê°€ ë” ë§ìœ¼ë¯€ë¡œ factor ê³±í•˜ê¸° Targetì´ 1ì¸ row ê°œìˆ˜ë§Œí¼ë§Œ Targetì´ 0ì¸ rowì—ì„œ ìƒ˜í”Œë§\n",
        "\n",
        "    X_zero1=X_zero.sample(scale_factor*total_target[0], random_state = 1)\n",
        "\n",
        "    # ìƒ˜í”Œë§ëœ rowì™€ Targetì´ 1ì¸ rowë¥¼ í•©ì³ì„œ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
        "\n",
        "    X=pd.concat([X_one,X_zero1], ignore_index=True)\n",
        "    y= X['target']\n",
        "    print(X.shape)\n",
        "    print(X.sample(10))\n",
        "\n",
        "    \n",
        "    X.drop([\"target\"],axis=1,inplace=True)\n",
        "    \n",
        "    # ìƒˆë¡œ ë§Œë“  ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ train test split\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=0.25, random_state = 1)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBflDSFFKbeI"
      },
      "source": [
        "### 3. ëª¨ë¸ë§ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTKa8AaiJ4o1",
        "outputId": "e0a19b25-d9ae-44b4-fd55-54fd3082f760"
      },
      "source": [
        "# Data Rebalancing\n",
        "\n",
        "X_train, X_test, y_train, y_test = balanced_sampling(train,3)\n",
        "\n",
        "# RandomSearchCVë¡œ ì°¾ì€ ìµœì íŒŒë¼ë¯¸í„°ë“¤ë¡œ ëª¨ë¸ ìƒì„±\n",
        "\n",
        "lgb = LGBMClassifier(bagging_fraction=0.85, bagging_freq=1, boost='gbdt',\n",
        "               boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
        "               feature_fraction=1, gamma=1, importance_type='split',\n",
        "               learning_rate=0.1, max_bin=256, max_depth=1,\n",
        "               min_child_samples=153, min_child_weight=0.1, min_split_gain=0.0,\n",
        "               n_estimators=4000, n_jobs=-1, num_leaves=4, num_threads=8,\n",
        "               objective='binary', random_state=1, reg_alpha=0.1,\n",
        "               reg_lambda=0, seed=500, silent=True, subsample=0.8,\n",
        "               subsample_for_bin=200000, subsample_freq=0)\n",
        "\n",
        "# ëª¨ë¸ ì í•©\n",
        "\n",
        "start_time = timer(None)\n",
        "lgb.fit(X_train, y_train)\n",
        "y_pred = lgb.predict(X_test)\n",
        "timer(start_time)\n",
        "\n",
        "# Validation setìœ¼ë¡œ ê³„ì‚°í•œ ì •í™•ë„ì™€ f1 score\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print('F1_score:', metrics.f1_score(y_test, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',\n",
            "       'var_7', 'var_8',\n",
            "       ...\n",
            "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
            "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
            "      dtype='object', length=201)\n",
            "<class 'numpy.ndarray'>\n",
            "             target         var_0  ...       var_198       var_199\n",
            "count  28000.000000  28000.000000  ...  28000.000000  28000.000000\n",
            "mean       0.100321     10.685383  ...     15.877575     -3.356697\n",
            "std        0.300433      3.065415  ...      3.004946     10.391826\n",
            "min        0.000000      1.283200  ...      7.193200    -38.852800\n",
            "25%        0.000000      8.451800  ...     13.824100    -11.219350\n",
            "50%        0.000000     10.525650  ...     15.944500     -2.868650\n",
            "75%        0.000000     12.763600  ...     18.063550      4.766275\n",
            "max        1.000000     19.701100  ...     25.323000     26.468800\n",
            "\n",
            "[8 rows x 201 columns]\n",
            "Target Size :  201 2809\n",
            "(11236, 201)\n",
            "       target    var_0   var_1    var_2  ...  var_196  var_197  var_198  var_199\n",
            "6382        0  16.5662 -4.2678  14.2718  ...   8.5487   7.9554  14.3415  -4.6063\n",
            "5397        0   8.1242  2.9702  12.1805  ...  -4.0832   6.9774   9.7002 -13.4593\n",
            "1921        1  11.3171  0.4952  11.2503  ...  13.8161   8.4968  20.0153  -8.6858\n",
            "360         1  13.3556 -2.5240   6.6086  ...   9.4828   9.3056  16.1065  15.1584\n",
            "4619        0  10.6162  0.0552  11.3256  ...   3.3011   7.8754  19.1256 -14.8585\n",
            "11003       0  13.7507 -0.5970   8.4447  ...  -0.6730   8.7692  20.8396   0.2797\n",
            "9695        0   7.9168 -8.5456  10.6925  ...   1.8368   9.0501  19.8623  -5.2471\n",
            "11097       0  11.0857  1.0471   9.9502  ...   8.2755   9.6097  15.9370   0.5107\n",
            "7040        0   8.9916 -6.4258  11.1993  ...   9.3005   8.8481  10.9294 -13.0438\n",
            "3166        0  15.2946 -1.9557  14.0617  ...  -3.2166   8.8047  18.2454  -7.7303\n",
            "\n",
            "[10 rows x 201 columns]\n",
            "\n",
            " Time taken: 0 hours 0 minutes and 18.95 seconds.\n",
            "Accuracy: 0.8444286222855109\n",
            "F1_score: 0.6484312148028962\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}